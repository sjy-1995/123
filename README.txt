This is the code for our paper "MoEP-AE: Autoencoding Mixtures of Exponential Power Distributions for Open-Set Recognition"[1], which has been published on T-CSVT.

Environments: Python 3.7.7, Pytorch 1.7.1, CUDA 10.1.105, GPU NVIDIA TITAN X

To train:

python train_MoEP_AE_macro_F1_scores.py

To test:

python eval_MoEP_AE_macro_F1_scores.py

[1] Jiayin Sun, Hong Wang, Qiulei Dong. MoEP-AE: Autoencoding Mixtures of Exponential Power Distributions for Open-Set Recognition[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2022, 33(1): 312-325.
